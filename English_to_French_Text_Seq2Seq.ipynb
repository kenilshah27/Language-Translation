{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "English to French Text Seq2Seq",
      "version": "0.3.2",
      "provenance": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZNG3pgYe_Qzm",
        "colab_type": "text"
      },
      "source": [
        "The dataset is taken from the site: http://www.manythings.org/anki/\n",
        "\n",
        "There are many datasets which could have been taken. I selected English to French as it had enough samples to train the model effectively."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BnvFtHXv-2RX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "import sys\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import io\n",
        "\n",
        "from keras.models import Model\n",
        "from keras.layers import Dense, Embedding, Input\n",
        "from keras.layers import LSTM, Bidirectional, GlobalMaxPool1D, Dropout,Concatenate\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.optimizers import Adam\n",
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sMWYaeG_-8YR",
        "colab_type": "code",
        "outputId": "4fe9a158-17f5-4223-bec5-84bf41823ad6",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 74
        }
      },
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-c0986f00-39ea-4b97-bfd7-b5aef9b4825c\" name=\"files[]\" multiple disabled />\n",
              "     <output id=\"result-c0986f00-39ea-4b97-bfd7-b5aef9b4825c\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving fra.txt to fra (1).txt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nY4NaVN5_v-H",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df = pd.read_table(io.BytesIO(uploaded['fra.txt']),header = None)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g9PKMOVyAeBj",
        "colab_type": "code",
        "outputId": "6905a295-cb4a-4890-c5ec-7de4de7dce15",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "#Dataset for the model\n",
        "\n",
        "df.columns = ['English','French']\n",
        "df.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>English</th>\n",
              "      <th>French</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Go.</td>\n",
              "      <td>Va !</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Hi.</td>\n",
              "      <td>Salut !</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Hi.</td>\n",
              "      <td>Salut.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Run!</td>\n",
              "      <td>Cours !</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Run!</td>\n",
              "      <td>Courez !</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  English    French\n",
              "0     Go.      Va !\n",
              "1     Hi.   Salut !\n",
              "2     Hi.    Salut.\n",
              "3    Run!   Cours !\n",
              "4    Run!  Courez !"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hNwUcZrABNaO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Setting Parameters\n",
        "\n",
        "BATCH_SIZE = 32            # Batch size for the training set. After each BATCH_SIZE the weights will be updated\n",
        "EPOCHS = 100               # Number of times we will train the model\n",
        "LSTM_units = 256           # Output nits for the LSTM Layer\n",
        "MAX_SEQUENCE_LENGTH = 100  # Maximum number of words in a single sentence\n",
        "VOCAB_SIZE = 20000         # Vocab size for the dataset\n",
        "EMBEDDING_DIM = 50         # Embedding units to represent a single word in English\n",
        "EMBEDDING_DIM_FRENCH = 100 # Embedding units to represent a single word in French"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bk2IVfhjCQIr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "english_text_input = df['English'][:15000].values                                 # Input for the training Encoder\n",
        "french_text_input = df['French'][:15000].apply(lambda x:'<sos> ' + x).values      # Input for the training Decoder\n",
        "french_text_output = df['French'][:15000].apply(lambda x:x + ' <eos>').values     # Output for the training Decoder\n",
        "\n",
        "# We are using <sos> and <eos> as we will be using Teacher Forcing."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OT4pXHk2C-_2",
        "colab_type": "code",
        "outputId": "a12b5082-988f-4ec5-8318-743c73af3417",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(\"Number of samples for the training data: \",len(english_text_input))  # 170190 samples"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of samples for the training data:  15000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7gGR3cAqDAT2",
        "colab_type": "code",
        "outputId": "99ac199c-2956-42cf-ff75-508e1b294c69",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Tokenize the English Text\n",
        "tokenizer_english = Tokenizer(num_words=VOCAB_SIZE)\n",
        "sentences = tokenizer_english.fit_on_texts(english_text_input)\n",
        "english_sequences_input = tokenizer_english.texts_to_sequences(english_text_input)\n",
        "english_sequences_input[:5]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[18], [668], [668], [146], [146]]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "088VejLCF7D2",
        "colab_type": "text"
      },
      "source": [
        "The words are now converted into numbers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GjcSsIkVGJSI",
        "colab_type": "code",
        "outputId": "6295c504-773f-466c-9636-953709d0b1d2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Get the word to index Mapping\n",
        "word2idx_english = tokenizer_english.word_index\n",
        "print('Unique english words: ',len(word2idx_english))    # Identified 14384 unique letters"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Unique english words:  2921\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Av5sRkyzDT22",
        "colab_type": "code",
        "outputId": "40fba3da-0938-41d7-d3a0-4171951132af",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "#Tokenize the French Text\n",
        "tokenizer_french = Tokenizer(num_words=VOCAB_SIZE,filters = '')\n",
        "sentences = tokenizer_french.fit_on_texts(french_text_input + french_text_output)  # We use both the dataset so that <sos> and <eos> are also included in the tokenize set of words\n",
        "french_sequences_input = tokenizer_french.texts_to_sequences(french_text_input)\n",
        "french_sequences_output = tokenizer_french.texts_to_sequences(french_text_output)\n",
        "print('Input: ',french_sequences_input[:5])\n",
        "print('Output: ',french_sequences_output[:5])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input:  [[1, 58, 6], [1, 1208, 6], [1], [1], [1]]\n",
            "Output:  [[58, 6, 2], [1208, 6, 2], [2], [2], [2]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M6DX_L2zHDaY",
        "colab_type": "code",
        "outputId": "2a46be4c-54dd-445a-da46-0af85c905287",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Get the word to index Mapping\n",
        "\n",
        "word2idx_french = tokenizer_french.word_index\n",
        "print('Unique french words: ',len(word2idx_french))    # Identified 14384 unique letters\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Unique french words:  16547\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SNZAqGn0HKo-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Getting Max length for both the texts\n",
        "max_english = max(len(s) for s in english_sequences_input)   # Max sequence length in English\n",
        "max_french = max(len(s) for s in french_sequences_input)     # Max sequence length in French\n",
        "num_words_french = len(word2idx_french) + 1                  # Possible outputs for the french language"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nsBtOwn-HVsf",
        "colab_type": "code",
        "outputId": "4be50ce7-bf18-40a4-d3e4-7ec2cf41030b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "# Padding the sequences\n",
        "\n",
        "encode_english_input = pad_sequences(english_sequences_input,maxlen = max_english,padding = 'post')\n",
        "decode_french_input = pad_sequences(french_sequences_input,maxlen = max_french,padding = 'post')\n",
        "decode_french_output = pad_sequences(french_sequences_output,maxlen = max_french,padding = 'post')\n",
        "\n",
        "# Size of the input and output\n",
        "\n",
        "print('Size of Encode Input: ',encode_english_input.shape)\n",
        "print('Size of Decode Input: ',decode_french_input.shape)\n",
        "print('Size of Decode Output: ',decode_french_output.shape)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Size of Encode Input:  (15000, 5)\n",
            "Size of Decode Input:  (15000, 12)\n",
            "Size of Decode Output:  (15000, 12)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6W9dXc4YKMzG",
        "colab_type": "code",
        "outputId": "1cc9d846-ea15-42ad-fa13-5bdcd0524f51",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Loading pretrained word vector\n",
        "\n",
        "word2vec = {}\n",
        "with open(os.path.join('/content/drive/My Drive/Colab Notebooks/Dataset/glove.6B.50d.txt')) as f:\n",
        "  for line in f:\n",
        "    values = line.split()\n",
        "    word = values[0]\n",
        "    vec = np.asarray(values[1:], dtype='float32')\n",
        "    word2vec[word] = vec\n",
        "print('Found %s word vectors.' % len(word2vec))\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 400000 word vectors.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3MjbWINzKpwt",
        "colab_type": "code",
        "outputId": "1be68ef3-c004-42b5-e6e0-9cf34ec8ad5d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "num_words = min(VOCAB_SIZE, len(word2idx_english) + 1)\n",
        "\n",
        "print('Number of words',num_words)\n",
        "\n",
        "embedding_matrix = np.zeros((num_words, EMBEDDING_DIM))  # Creating the embedding matrix with each word having dimension of 50\n",
        "print('Shape of Embedding Matrix',embedding_matrix.shape)\n",
        "\n",
        "for word, i in word2idx_english.items():\n",
        "  if i < VOCAB_SIZE:\n",
        "    embedding_vector = word2vec.get(word)\n",
        "    if embedding_vector is not None:\n",
        "      # words not found in embedding index will be all zeros.\n",
        "      embedding_matrix[i] = embedding_vector\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of words 2922\n",
            "Shape of Embedding Matrix (2922, 50)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SmRcLBZsLPVH",
        "colab_type": "code",
        "outputId": "4c7ffe5f-2a70-42e5-d8fa-87d53dc77231",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        }
      },
      "source": [
        "embedding_matrix"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n",
              "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
              "       [ 1.18910000e-01,  1.52549997e-01, -8.20730031e-02, ...,\n",
              "        -5.75119972e-01, -2.66710013e-01,  9.21209991e-01],\n",
              "       [-1.09190005e-03,  3.33240002e-01,  3.57430011e-01, ...,\n",
              "        -4.56970006e-01, -4.89690006e-02,  1.13160002e+00],\n",
              "       ...,\n",
              "       [ 2.15690002e-01, -9.00229990e-01,  6.82510018e-01, ...,\n",
              "         4.65460002e-01,  1.81079999e-01, -1.22239999e-01],\n",
              "       [ 9.63559985e-01, -5.39669991e-01,  2.77429998e-01, ...,\n",
              "        -3.87650013e-01,  1.31150007e-01,  6.29419982e-01],\n",
              "       [-4.29910004e-01,  5.82780004e-01, -8.21919963e-02, ...,\n",
              "        -6.38769984e-01, -6.83719963e-02, -8.71749997e-01]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1UddAM0nOs-g",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JWdD-GHVLcEe",
        "colab_type": "text"
      },
      "source": [
        "# MODEL CREATION"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XpW-lu6oLfGu",
        "colab_type": "code",
        "outputId": "9cc51f7b-1cbb-4cb9-ee15-ba404aa66940",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        }
      },
      "source": [
        "# Embedding Layer\n",
        "\n",
        "embedding_layer = Embedding(input_dim = num_words, output_dim = EMBEDDING_DIM, weights = [embedding_matrix],input_length = max_english)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W0723 20:32:34.286412 140518383687552 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kkaGbsGPMJxM",
        "colab_type": "code",
        "outputId": "2b8dcea0-037c-40d0-dd80-f564f658759f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Creating the target variable\n",
        "\n",
        "decoder_target_onehot = np.zeros((len(english_text_input),max_french,num_words_french),dtype = 'float32')\n",
        "print('Shape: ',decoder_target_onehot.shape)   \n",
        "\n",
        "# 10000 represents each sequence\n",
        "# 11 represents max length in english\n",
        "# 11903 represents max length in french"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Shape:  (15000, 12, 16548)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2PhTdCQfMuAy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Assiging the values to the output\n",
        "\n",
        "for i,d in enumerate(decode_french_output):\n",
        "  for t,word in enumerate(d):\n",
        "    decoder_target_onehot[i,t,word] = 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hLEzNK2DQfPf",
        "colab_type": "text"
      },
      "source": [
        "## Adding Layers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WzM3BIuJQAuH",
        "colab_type": "code",
        "outputId": "b9fabdd3-3445-4cb9-ad4f-e940622879af",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "encoder_input = Input(shape = (max_english,))  # Assigning input for the encoder\n",
        "\n",
        "print(encoder_input.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(?, 5)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "525vExlPQ4Pw",
        "colab_type": "code",
        "outputId": "44e105df-5846-46aa-fe20-f458340566e0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "x = embedding_layer(encoder_input)            # Embedding the words from the input\n",
        "print(x.shape)\n",
        "\n",
        "# Each of the words will now be represented by 50 values"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(?, 5, 50)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uaYtY0eMRIsX",
        "colab_type": "code",
        "outputId": "50cb1dc9-5660-4f33-a184-8e34f40fcc25",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "encoder_lstm = Bidirectional(LSTM(LSTM_units,return_state = True,dropout = 0.2))   # return_states is True so that it will return hidden state and cell values to pass it to decoder\n",
        "encoder_output,hidden_state_f,hidden_state_b,cell_state_f,cell_state_b= encoder_lstm(x)\n",
        "\n",
        "print(encoder_output.shape)    # Only the output from the last cell is taken hence shape is (?,256)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(?, 512)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TwyOIrURR0Eo",
        "colab_type": "code",
        "outputId": "bb8cf635-b822-422c-ebe3-856967ee7481",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "hidden_state = Concatenate()([hidden_state_f, hidden_state_b])\n",
        "cell_state = Concatenate()([cell_state_f, cell_state_b])\n",
        "\n",
        "encoder_states = [hidden_state,cell_state]   # Storing the hidden state and cell state so that it can be passed to decoder as initial state\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorShape([Dimension(None), Dimension(512)])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 179
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f5F69laYSUvf",
        "colab_type": "code",
        "outputId": "bb3bfbf3-0876-4a4a-8b63-d40a416013c7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "decoder_input = Input(shape = (max_french,))   # Assigning input for the decoder\n",
        "\n",
        "print(decoder_input.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(?, 12)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x3F3fguGSnqP",
        "colab_type": "code",
        "outputId": "e073718b-1a9c-4e30-9175-1b9137e26b5b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "decoder_embedding = Embedding(num_words_french,EMBEDDING_DIM_FRENCH)   # Performing Embedding for French\n",
        "decoder_input_emb = decoder_embedding(decoder_input)                   # Embedding the words from the input \n",
        "\n",
        "print(decoder_input_emb.shape)\n",
        "\n",
        "# Each of the words will now be represented by 100 values"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(?, 12, 100)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oPO9_xD_TTAv",
        "colab_type": "code",
        "outputId": "461e0bf2-3383-4dce-deb6-f1cac269bb40",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "decoder_lstm = LSTM(LSTM_units*2,return_sequences = True,return_state = True,dropout = 0.2)\n",
        "\n",
        "# return sequences is True so that it returns output at every instance\n",
        "# return state is True so that the state from given time step can be passed onto the next time step\n",
        "\n",
        "decoder_output,_,_= decoder_lstm(decoder_input_emb,initial_state = encoder_states)\n",
        "\n",
        "# Not storing hidden state and cell state as it is not required now but will be used while doing the prediction\n",
        "\n",
        "print(decoder_output.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(?, ?, 512)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PcA9GVPXUEbu",
        "colab_type": "code",
        "outputId": "483f5171-db0f-4479-8414-1958078b61cf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "# Dense layer to get the probability of each word\n",
        "\n",
        "decoder_dense_layer_1 = Dense(2048,activation = 'relu')\n",
        "decoder_output = decoder_dense_layer_1(decoder_output)\n",
        "print(decoder_output.shape) \n",
        "\n",
        "decoder_dense_layer_2 = Dense(1024,activation = 'relu')\n",
        "decoder_output = decoder_dense_layer_2(decoder_output)\n",
        "print(decoder_output.shape) \n",
        "\n",
        "decoder_dense_layer_3 = Dense(512,activation = 'relu')\n",
        "decoder_output = decoder_dense_layer_3(decoder_output)\n",
        "print(decoder_output.shape) \n",
        "\n",
        "decoder_dense_layer_4 = Dense(256,activation = 'relu')\n",
        "decoder_output = decoder_dense_layer_4(decoder_output)\n",
        "print(decoder_output.shape) \n",
        "\n",
        "decoder_dense = Dense(num_words_french,activation = 'softmax')\n",
        "decoder_output = decoder_dense(decoder_output)\n",
        "\n",
        "print(decoder_output.shape) \n",
        "\n",
        "# Each word in the sequence is now represent by 11903 probabilities. The word with the highest probability will be selected."
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(?, 12, 2048)\n",
            "(?, 12, 1024)\n",
            "(?, 12, 512)\n",
            "(?, 12, 256)\n",
            "(?, 12, 16548)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RzLbiSs8UYj3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = Model([encoder_input,decoder_input],decoder_output)\n",
        "\n",
        "model.compile(optimizer = 'rmsprop',loss = 'categorical_crossentropy',metrics = ['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6bEjXSfqVE1m",
        "colab_type": "code",
        "outputId": "d978ae18-a7c0-4676-abe3-a04bf51eb5fb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "r = model.fit([encode_english_input,decode_french_input],decoder_target_onehot,epochs = EPOCHS,batch_size=BATCH_SIZE)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "15000/15000 [==============================] - 37s 2ms/step - loss: 2.0269 - acc: 0.7181\n",
            "Epoch 2/100\n",
            "15000/15000 [==============================] - 31s 2ms/step - loss: 1.5388 - acc: 0.7767\n",
            "Epoch 3/100\n",
            "15000/15000 [==============================] - 31s 2ms/step - loss: 1.3360 - acc: 0.7988\n",
            "Epoch 4/100\n",
            "15000/15000 [==============================] - 31s 2ms/step - loss: 1.2185 - acc: 0.8124\n",
            "Epoch 5/100\n",
            "15000/15000 [==============================] - 31s 2ms/step - loss: 1.1463 - acc: 0.8202\n",
            "Epoch 6/100\n",
            "15000/15000 [==============================] - 31s 2ms/step - loss: 1.0799 - acc: 0.8278\n",
            "Epoch 7/100\n",
            "15000/15000 [==============================] - 31s 2ms/step - loss: 1.0302 - acc: 0.8331\n",
            "Epoch 8/100\n",
            "15000/15000 [==============================] - 31s 2ms/step - loss: 0.9888 - acc: 0.8371\n",
            "Epoch 9/100\n",
            "15000/15000 [==============================] - 31s 2ms/step - loss: 0.9466 - acc: 0.8414\n",
            "Epoch 10/100\n",
            "15000/15000 [==============================] - 31s 2ms/step - loss: 0.9047 - acc: 0.8453\n",
            "Epoch 11/100\n",
            "15000/15000 [==============================] - 31s 2ms/step - loss: 0.8714 - acc: 0.8494\n",
            "Epoch 12/100\n",
            "15000/15000 [==============================] - 31s 2ms/step - loss: 0.8370 - acc: 0.8531\n",
            "Epoch 13/100\n",
            "15000/15000 [==============================] - 31s 2ms/step - loss: 0.8057 - acc: 0.8564\n",
            "Epoch 14/100\n",
            "15000/15000 [==============================] - 31s 2ms/step - loss: 0.7782 - acc: 0.8607\n",
            "Epoch 15/100\n",
            "15000/15000 [==============================] - 31s 2ms/step - loss: 0.7560 - acc: 0.8635\n",
            "Epoch 16/100\n",
            "15000/15000 [==============================] - 31s 2ms/step - loss: 0.7303 - acc: 0.8664\n",
            "Epoch 17/100\n",
            "15000/15000 [==============================] - 31s 2ms/step - loss: 0.7094 - acc: 0.8692\n",
            "Epoch 18/100\n",
            "15000/15000 [==============================] - 31s 2ms/step - loss: 0.8576 - acc: 0.8622\n",
            "Epoch 19/100\n",
            "15000/15000 [==============================] - 31s 2ms/step - loss: 0.6870 - acc: 0.8742\n",
            "Epoch 20/100\n",
            "15000/15000 [==============================] - 31s 2ms/step - loss: 0.6726 - acc: 0.8764\n",
            "Epoch 21/100\n",
            "15000/15000 [==============================] - 31s 2ms/step - loss: 0.6533 - acc: 0.8792\n",
            "Epoch 22/100\n",
            "15000/15000 [==============================] - 31s 2ms/step - loss: 0.6366 - acc: 0.8808\n",
            "Epoch 23/100\n",
            "15000/15000 [==============================] - 31s 2ms/step - loss: 0.6183 - acc: 0.8832\n",
            "Epoch 24/100\n",
            "15000/15000 [==============================] - 32s 2ms/step - loss: 0.5975 - acc: 0.8848\n",
            "Epoch 25/100\n",
            "15000/15000 [==============================] - 31s 2ms/step - loss: 0.5840 - acc: 0.8872\n",
            "Epoch 26/100\n",
            "15000/15000 [==============================] - 31s 2ms/step - loss: 0.5901 - acc: 0.8881\n",
            "Epoch 27/100\n",
            "15000/15000 [==============================] - 31s 2ms/step - loss: 0.5888 - acc: 0.8888\n",
            "Epoch 28/100\n",
            "15000/15000 [==============================] - 31s 2ms/step - loss: 0.5742 - acc: 0.8908\n",
            "Epoch 29/100\n",
            "15000/15000 [==============================] - 31s 2ms/step - loss: 0.5601 - acc: 0.8928\n",
            "Epoch 30/100\n",
            "15000/15000 [==============================] - 31s 2ms/step - loss: 0.5527 - acc: 0.8930\n",
            "Epoch 31/100\n",
            "15000/15000 [==============================] - 31s 2ms/step - loss: 0.5369 - acc: 0.8948\n",
            "Epoch 32/100\n",
            "15000/15000 [==============================] - 31s 2ms/step - loss: 0.5251 - acc: 0.8962\n",
            "Epoch 33/100\n",
            "15000/15000 [==============================] - 31s 2ms/step - loss: 0.5183 - acc: 0.8971\n",
            "Epoch 34/100\n",
            "15000/15000 [==============================] - 31s 2ms/step - loss: 0.5126 - acc: 0.8982\n",
            "Epoch 35/100\n",
            "15000/15000 [==============================] - 31s 2ms/step - loss: 0.4988 - acc: 0.8994\n",
            "Epoch 36/100\n",
            "15000/15000 [==============================] - 31s 2ms/step - loss: 0.4946 - acc: 0.9005\n",
            "Epoch 37/100\n",
            "15000/15000 [==============================] - 31s 2ms/step - loss: 0.4900 - acc: 0.9018\n",
            "Epoch 38/100\n",
            "15000/15000 [==============================] - 31s 2ms/step - loss: 0.4856 - acc: 0.9014\n",
            "Epoch 39/100\n",
            "15000/15000 [==============================] - 31s 2ms/step - loss: 0.4826 - acc: 0.9031\n",
            "Epoch 40/100\n",
            "15000/15000 [==============================] - 31s 2ms/step - loss: 0.4779 - acc: 0.9037\n",
            "Epoch 41/100\n",
            "15000/15000 [==============================] - 31s 2ms/step - loss: 0.4822 - acc: 0.9039\n",
            "Epoch 42/100\n",
            "15000/15000 [==============================] - 31s 2ms/step - loss: 0.4787 - acc: 0.9047\n",
            "Epoch 43/100\n",
            "15000/15000 [==============================] - 31s 2ms/step - loss: 0.4755 - acc: 0.9056\n",
            "Epoch 44/100\n",
            "15000/15000 [==============================] - 31s 2ms/step - loss: 0.4651 - acc: 0.9066\n",
            "Epoch 45/100\n",
            "15000/15000 [==============================] - 31s 2ms/step - loss: 0.4598 - acc: 0.9069\n",
            "Epoch 46/100\n",
            "15000/15000 [==============================] - 31s 2ms/step - loss: 0.4497 - acc: 0.9079\n",
            "Epoch 47/100\n",
            "15000/15000 [==============================] - 32s 2ms/step - loss: 0.4530 - acc: 0.9085\n",
            "Epoch 48/100\n",
            "15000/15000 [==============================] - 31s 2ms/step - loss: 0.4549 - acc: 0.9091\n",
            "Epoch 49/100\n",
            "15000/15000 [==============================] - 31s 2ms/step - loss: 0.4595 - acc: 0.9092\n",
            "Epoch 50/100\n",
            "15000/15000 [==============================] - 31s 2ms/step - loss: 0.4588 - acc: 0.9100\n",
            "Epoch 51/100\n",
            "15000/15000 [==============================] - 31s 2ms/step - loss: 0.4511 - acc: 0.9113\n",
            "Epoch 52/100\n",
            "15000/15000 [==============================] - 31s 2ms/step - loss: 0.4422 - acc: 0.9125\n",
            "Epoch 53/100\n",
            "15000/15000 [==============================] - 31s 2ms/step - loss: 0.4414 - acc: 0.9125\n",
            "Epoch 54/100\n",
            "15000/15000 [==============================] - 32s 2ms/step - loss: 0.4394 - acc: 0.9129\n",
            "Epoch 55/100\n",
            "15000/15000 [==============================] - 31s 2ms/step - loss: 0.4275 - acc: 0.9138\n",
            "Epoch 56/100\n",
            "15000/15000 [==============================] - 31s 2ms/step - loss: 0.4267 - acc: 0.9138\n",
            "Epoch 57/100\n",
            "15000/15000 [==============================] - 31s 2ms/step - loss: 0.4197 - acc: 0.9144\n",
            "Epoch 58/100\n",
            "15000/15000 [==============================] - 31s 2ms/step - loss: 0.4114 - acc: 0.9160\n",
            "Epoch 59/100\n",
            "15000/15000 [==============================] - 31s 2ms/step - loss: 0.4127 - acc: 0.9157\n",
            "Epoch 60/100\n",
            "15000/15000 [==============================] - 31s 2ms/step - loss: 0.4083 - acc: 0.9161\n",
            "Epoch 61/100\n",
            "15000/15000 [==============================] - 31s 2ms/step - loss: 0.3997 - acc: 0.9172\n",
            "Epoch 62/100\n",
            "15000/15000 [==============================] - 31s 2ms/step - loss: 0.4004 - acc: 0.9174\n",
            "Epoch 63/100\n",
            "15000/15000 [==============================] - 31s 2ms/step - loss: 0.4003 - acc: 0.9174\n",
            "Epoch 64/100\n",
            "15000/15000 [==============================] - 32s 2ms/step - loss: 0.3939 - acc: 0.9181\n",
            "Epoch 65/100\n",
            "15000/15000 [==============================] - 31s 2ms/step - loss: 0.4028 - acc: 0.9183\n",
            "Epoch 66/100\n",
            "15000/15000 [==============================] - 31s 2ms/step - loss: 0.3906 - acc: 0.9186\n",
            "Epoch 67/100\n",
            "15000/15000 [==============================] - 31s 2ms/step - loss: 0.3852 - acc: 0.9197\n",
            "Epoch 68/100\n",
            "15000/15000 [==============================] - 31s 2ms/step - loss: 0.3831 - acc: 0.9202\n",
            "Epoch 69/100\n",
            "15000/15000 [==============================] - 31s 2ms/step - loss: 0.3907 - acc: 0.9187\n",
            "Epoch 70/100\n",
            "15000/15000 [==============================] - 31s 2ms/step - loss: 0.3854 - acc: 0.9201\n",
            "Epoch 71/100\n",
            "15000/15000 [==============================] - 31s 2ms/step - loss: 0.3856 - acc: 0.9198\n",
            "Epoch 72/100\n",
            "15000/15000 [==============================] - 31s 2ms/step - loss: 0.3810 - acc: 0.9199\n",
            "Epoch 73/100\n",
            "15000/15000 [==============================] - 31s 2ms/step - loss: 0.3788 - acc: 0.9209\n",
            "Epoch 74/100\n",
            "15000/15000 [==============================] - 32s 2ms/step - loss: 0.3756 - acc: 0.9219\n",
            "Epoch 75/100\n",
            "15000/15000 [==============================] - 31s 2ms/step - loss: 0.3764 - acc: 0.9216\n",
            "Epoch 76/100\n",
            "15000/15000 [==============================] - 31s 2ms/step - loss: 0.3731 - acc: 0.9217\n",
            "Epoch 77/100\n",
            "15000/15000 [==============================] - 31s 2ms/step - loss: 0.3694 - acc: 0.9226\n",
            "Epoch 78/100\n",
            "15000/15000 [==============================] - 31s 2ms/step - loss: 0.3666 - acc: 0.9224\n",
            "Epoch 79/100\n",
            "15000/15000 [==============================] - 31s 2ms/step - loss: 0.3732 - acc: 0.9226\n",
            "Epoch 80/100\n",
            "15000/15000 [==============================] - 31s 2ms/step - loss: 0.3650 - acc: 0.9231\n",
            "Epoch 81/100\n",
            "15000/15000 [==============================] - 31s 2ms/step - loss: 0.3715 - acc: 0.9227\n",
            "Epoch 82/100\n",
            "15000/15000 [==============================] - 31s 2ms/step - loss: 0.3630 - acc: 0.9236\n",
            "Epoch 83/100\n",
            "15000/15000 [==============================] - 31s 2ms/step - loss: 0.3673 - acc: 0.9234\n",
            "Epoch 84/100\n",
            "15000/15000 [==============================] - 32s 2ms/step - loss: 0.3598 - acc: 0.9245\n",
            "Epoch 85/100\n",
            "15000/15000 [==============================] - 31s 2ms/step - loss: 0.3564 - acc: 0.9248\n",
            "Epoch 86/100\n",
            "15000/15000 [==============================] - 31s 2ms/step - loss: 0.3622 - acc: 0.9243\n",
            "Epoch 87/100\n",
            "15000/15000 [==============================] - 31s 2ms/step - loss: 0.3673 - acc: 0.9238\n",
            "Epoch 88/100\n",
            "15000/15000 [==============================] - 31s 2ms/step - loss: 0.3716 - acc: 0.9243\n",
            "Epoch 89/100\n",
            "15000/15000 [==============================] - 31s 2ms/step - loss: 0.4056 - acc: 0.9218\n",
            "Epoch 90/100\n",
            "15000/15000 [==============================] - 31s 2ms/step - loss: 0.3657 - acc: 0.9246\n",
            "Epoch 91/100\n",
            "15000/15000 [==============================] - 31s 2ms/step - loss: 0.3621 - acc: 0.9254\n",
            "Epoch 92/100\n",
            "15000/15000 [==============================] - 31s 2ms/step - loss: 0.3583 - acc: 0.9258\n",
            "Epoch 93/100\n",
            "15000/15000 [==============================] - 31s 2ms/step - loss: 0.3594 - acc: 0.9259\n",
            "Epoch 94/100\n",
            "15000/15000 [==============================] - 32s 2ms/step - loss: 0.3575 - acc: 0.9263\n",
            "Epoch 95/100\n",
            "15000/15000 [==============================] - 31s 2ms/step - loss: 0.3644 - acc: 0.9258\n",
            "Epoch 96/100\n",
            "15000/15000 [==============================] - 31s 2ms/step - loss: 0.3625 - acc: 0.9259\n",
            "Epoch 97/100\n",
            "15000/15000 [==============================] - 31s 2ms/step - loss: 0.3608 - acc: 0.9262\n",
            "Epoch 98/100\n",
            "15000/15000 [==============================] - 31s 2ms/step - loss: 0.3561 - acc: 0.9271\n",
            "Epoch 99/100\n",
            "15000/15000 [==============================] - 31s 2ms/step - loss: 0.3590 - acc: 0.9267\n",
            "Epoch 100/100\n",
            "15000/15000 [==============================] - 31s 2ms/step - loss: 0.3532 - acc: 0.9270\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RN5d_DoDVRlH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.save('EngToFra.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BL50vgeGJz40",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0_OLfKbfV_ww",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "encoder_model = Model(encoder_input,encoder_states)   # Creating an encoder_model so that we can take the hidden states and cell states for the input sequence"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MxcL-bjeWUJf",
        "colab_type": "code",
        "outputId": "c0b0de3d-9e97-4eac-c093-e245e677bbbd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "decoder_state_h = Input(shape = (LSTM_units*2,))   # Setting input of hidden state for the decoder for predicting\n",
        "decoder_state_c = Input(shape = (LSTM_units*2,))   # Setting input of cell state for the decoder for predicting\n",
        "\n",
        "decoder_state_input = [decoder_state_h,decoder_state_c]\n",
        "print(decoder_state_input[1].shape)\n",
        "print(encoder_states[1].shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(?, 512)\n",
            "(?, 512)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-AhSAOz5WvaO",
        "colab_type": "code",
        "outputId": "a34ee173-ac86-4a63-ce31-00b94a39fcda",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "decoder_input_word = Input(shape = (1,))     # Expecting one word for the input\n",
        "\n",
        "print(decoder_input_word.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(?, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TsPfpgwWW95x",
        "colab_type": "code",
        "outputId": "7c2b177c-270e-4911-9bb5-261b9b37595d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "decoder_input_word_emb = decoder_embedding(decoder_input_word)   # Embedding the input for the decoder\n",
        "\n",
        "print(decoder_input_word_emb.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(?, 1, 100)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_hPlA2zYXJL_",
        "colab_type": "code",
        "outputId": "47b68b23-1b3e-4f50-a2e7-2c5201489d63",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "decoder_output,hidden_state_decoder,cell_state_decoder = decoder_lstm(decoder_input_word_emb,initial_state = decoder_state_input)\n",
        "\n",
        "decoder_state = [hidden_state_decoder,cell_state_decoder]\n",
        "\n",
        "print(decoder_output.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(?, ?, 512)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7focbsE7XjC3",
        "colab_type": "code",
        "outputId": "e882d01b-5787-4e29-b531-74fcaa4fce76",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "decoder_output = decoder_dense_layer_1(decoder_output)\n",
        "decoder_output = decoder_dense_layer_2(decoder_output)\n",
        "decoder_output = decoder_dense_layer_3(decoder_output)\n",
        "decoder_output = decoder_dense_layer_4(decoder_output)\n",
        "\n",
        "decoder_output = decoder_dense(decoder_output)\n",
        "\n",
        "print(decoder_output.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(?, 1, 16548)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QwrzT-SFXnoP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "decoder_model = Model([decoder_input_word] + decoder_state_input,[decoder_output] + decoder_state)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cHOeXgIIX8MX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "idx2words_english = {v:k for k,v in word2idx_english.items()}   # mapping from integer to word for english\n",
        "idx2words_french = {v:k for k,v in word2idx_french.items()}     # mapping from integer to word for french\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s-2mSLWfYUx1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def decode_sequences(input_sequence):\n",
        "  \n",
        "  encode_states = encoder_model.predict(input_sequence)  # To get the states for the particular input sequence\n",
        "  \n",
        "  target = np.zeros((1,1))   # Creating a space for the target word or the next word that will be predicted. Since a single word will be predicted the shape is (1,1)\n",
        "  \n",
        "  target[0,0] = word2idx_french['<sos>']  # since we will be staring with <sos>\n",
        "  \n",
        "  eos_idx = word2idx_french['<eos>']          # If we find this stop predicting\n",
        "  \n",
        "  output_sequence = []   # To store the entire predicted sequence\n",
        "  \n",
        "  for _ in range(max_french):\n",
        "    \n",
        "    output_prob,h,c = decoder_model.predict([target] + encode_states)   # Predicting the next word and storing h and c for further use\n",
        "    \n",
        "    idx_of_predicted_word = np.argmax(output_prob[0,0,:])    # Taking the probability for all the words\n",
        "\n",
        "    if eos_idx == idx_of_predicted_word:         # If we found the end of sentence tag\n",
        "      break\n",
        "    \n",
        "    if idx_of_predicted_word > 0:                                # Since 0 will be stored for unknown words\n",
        "      predicted_word = idx2words_french[idx_of_predicted_word]   # Converting the predicted index to its corresponding word\n",
        "      output_sequence.append(predicted_word)                     # Storing it into the sequence\n",
        "      \n",
        "    \n",
        "    target[0,0] = idx_of_predicted_word\n",
        "    \n",
        "    encode_states = [h,c]\n",
        "  \n",
        "  return \" \".join(output_sequence)\n",
        "    \n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q3vnknK5aq20",
        "colab_type": "code",
        "outputId": "43953f7b-c5ff-4397-8fe7-8a3f549c95c1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 353
        }
      },
      "source": [
        "while(True):\n",
        "  \n",
        "  i = np.random.choice(len(english_text_input))\n",
        "  \n",
        "  input_sequence = encode_english_input[i:i+1]\n",
        "  \n",
        "  translation = decode_sequences(input_sequence)\n",
        "  \n",
        "  print('-')\n",
        "  \n",
        "  print('Input: ', english_text_input[i])\n",
        "  print('Expected: ', french_text_input[i])\n",
        "  print('Translation: ', translation)\n",
        "  \n",
        "  ans = input(\"Continue?\")\n",
        "  \n",
        "  if ans and ans.lower().startswith('n'):\n",
        "    break\n",
        "    \n",
        "    \n",
        "  "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "-\n",
            "Input:  I hate to lose.\n",
            "Expected:  <sos> Je déteste perdre.\n",
            "Translation:  je déteste parler.\n",
            "Continue?y\n",
            "-\n",
            "Input:  Go back to bed.\n",
            "Expected:  <sos> Retournez au lit !\n",
            "Translation:  retourne au lit !\n",
            "Continue?y\n",
            "-\n",
            "Input:  I'm by your side.\n",
            "Expected:  <sos> Je suis à vos côtés.\n",
            "Translation:  je suis à votre côté.\n",
            "Continue?y\n",
            "-\n",
            "Input:  See below.\n",
            "Expected:  <sos> Voir ci-dessous.\n",
            "Translation:  voyez ci-dessous.\n",
            "Continue?n\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ziluTN5heqfH",
        "colab_type": "code",
        "outputId": "8fe137ef-c519-49b4-ffe0-d6865083569a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "text = ['I love you']\n",
        "\n",
        "question = pad_sequences(tokenizer_english.texts_to_sequences(text),maxlen=max_english,padding = 'post')\n",
        "decode_sequences(question)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"je t'aime !\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 219
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z9Y8RVCSLaAf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}